{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsuo/miniconda3/envs/toy_flood/lib/python3.7/site-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as onp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib\n",
    "import timecast as tc\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timecast.learners._ar import _ar_gram\n",
    "from timecast.learners._pcr import _compute_pca_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "basins = pickle.load(open(\"../data/basins.p\", \"rb\"))\n",
    "\n",
    "def generator():\n",
    "    for basin in basins:\n",
    "        X = pickle.load(open(\"../data/train/{}.p\".format(basin), \"rb\"))\n",
    "        ealstm = pickle.load(open(\"../data/ealstm/{}.p\".format(basin), \"rb\"))\n",
    "        Y = onp.zeros((X.shape[0], 1))\n",
    "        Y[-ealstm.shape[0]:, :] = ealstm[[\"qobs\"]]\n",
    "        yield X[:, :5], Y, None\n",
    "            \n",
    "XTX, XTY = _ar_gram(generator(), input_dim=5, output_dim=1, history_len=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7b080d5031409db3729353aba3d195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "projections = {}\n",
    "for k in tqdm.tqdm([10, 50, 100, 500, 1000, 5000]):\n",
    "    projections[k] = _compute_pca_projection(XTX.matrix(normalize=True), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = pickle.load(open(\"../data/basins.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tc.experiment(\"k,projection\", projections.items())\n",
    "@tc.experiment(\"basin\", basins)\n",
    "def runner(basin, k, projection, lr=1e-5):\n",
    "    import pickle\n",
    "    from ealstm.gaip.utils import MSE\n",
    "\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from timecast.learners import Sequential, Parallel, Index, PCR\n",
    "    from timecast import smap\n",
    "    from timecast.objectives import residual\n",
    "    from timecast.optim import GradientDescent\n",
    "\n",
    "    import tqdm.notebook as tqdm\n",
    "    \n",
    "    X = pickle.load(open(\"../data/test/{}.p\".format(basin), \"rb\"))\n",
    "    Y = pickle.load(open(\"../data/ealstm/{}.p\".format(basin), \"rb\"))\n",
    "    \n",
    "    history_len = 270\n",
    "    \n",
    "    lstm = Index.partial(index=0)\n",
    "    pcr = PCR.partial(projection=projection, history_len=history_len, history=X[:history_len - 1])\n",
    "    pcr = Sequential.partial(learners=[Index.partial(index=1), pcr])\n",
    "    model, state = Parallel.new(shape=(1, 32), learners=[lstm, pcr])\n",
    "    \n",
    "    optim_def = GradientDescent(learning_rate=lr)\n",
    "    optimizer = optim_def.create(model)\n",
    "\n",
    "    # NOTE: difference in indexing convention, so need to pad one row\n",
    "    X_t = X[history_len - 1:]\n",
    "    Y_lstm = jnp.array(Y.qsim)\n",
    "    Y = jnp.array(Y.qobs).reshape(-1, 1)\n",
    "\n",
    "    Y_hat, optimizer, state = smap((Y_lstm, X_t), Y, optimizer, state=state, objective=residual)\n",
    "\n",
    "    return {\"basin\": basin, \"k\": k, \"mse\": MSE(Y, Y_hat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303b1dc51286455c8dcf5a6a12850b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = runner.run(processes=10, tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a893a4f62bf4e91b16c5c2eb485ae85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE (k=10): 2.7545559406280518\n",
      "Average MSE (k=50): 2.739213466644287\n",
      "Average MSE (k=100): 2.7256996631622314\n",
      "Average MSE (k=500): 2.712125062942505\n",
      "Average MSE (k=1000): 2.7122278213500977\n",
      "Average MSE (k=5000): 2.712256908416748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm.tqdm([10, 50, 100, 500, 1000, 5000]):\n",
    "    print(\"Average MSE (k={}): {}\".format(k, jnp.average(jnp.array([result[\"mse\"] for result in results if result[\"k\"] == k]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tc.experiment(\"k,projection\", [(500, projections[500])])\n",
    "@tc.experiment(\"basin\", basins)\n",
    "@tc.experiment(\"lr\", [10 ** -8, 10 ** -7.5, 10 ** -7, 10 ** -6.5, 10 ** -6, 10 ** -5.5, 10 ** -5, 10 ** -4.5, 10 ** -4, 10 ** -3.5])\n",
    "def runner(basin, k, projection, lr=1e-5):\n",
    "    import pickle\n",
    "    from ealstm.gaip.utils import MSE\n",
    "\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from timecast.learners import Sequential, Parallel, Index, PCR\n",
    "    from timecast import smap\n",
    "    from timecast.objectives import residual\n",
    "    from timecast.optim import GradientDescent\n",
    "\n",
    "    import tqdm.notebook as tqdm\n",
    "    \n",
    "    X = pickle.load(open(\"../data/test/{}.p\".format(basin), \"rb\"))\n",
    "    Y = pickle.load(open(\"../data/ealstm/{}.p\".format(basin), \"rb\"))\n",
    "    \n",
    "    history_len = 270\n",
    "    \n",
    "    lstm = Index.partial(index=0)\n",
    "    pcr = PCR.partial(projection=projection, history_len=history_len, history=X[:history_len - 1])\n",
    "    pcr = Sequential.partial(learners=[Index.partial(index=1), pcr])\n",
    "    model, state = Parallel.new(shape=(1, 32), learners=[lstm, pcr])\n",
    "    \n",
    "    optim_def = GradientDescent(learning_rate=lr)\n",
    "    optimizer = optim_def.create(model)\n",
    "\n",
    "    # NOTE: difference in indexing convention, so need to pad one row\n",
    "    X_t = X[history_len - 1:]\n",
    "    Y_lstm = jnp.array(Y.qsim)\n",
    "    Y = jnp.array(Y.qobs).reshape(-1, 1)\n",
    "\n",
    "    Y_hat, optimizer, state = smap((Y_lstm, X_t), Y, optimizer, state=state, objective=residual)\n",
    "\n",
    "    return {\"basin\": basin, \"k\": k, \"lr\": lr, \"mse\": MSE(Y, Y_hat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbe361da0bb4bdea491199870072136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = runner.run(processes=15, tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d89615498f45d2bd6cb621f5984410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE (lr=0.0000000100): 3.13\n",
      "Average MSE (lr=0.0000000316): 3.11\n",
      "Average MSE (lr=0.0000001000): 3.09\n",
      "Average MSE (lr=0.0000003162): 3.05\n",
      "Average MSE (lr=0.0000010000): 2.96\n",
      "Average MSE (lr=0.0000031623): 2.84\n",
      "Average MSE (lr=0.0000100000): 2.71\n",
      "Average MSE (lr=0.0000316228): nan\n",
      "Average MSE (lr=0.0001000000): nan\n",
      "Average MSE (lr=0.0003162278): nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in tqdm.tqdm([10 ** -8, 10 ** -7.5, 10 ** -7, 10 ** -6.5, 10 ** -6, 10 ** -5.5, 10 ** -5, 10 ** -4.5, 10 ** -4, 10 ** -3.5]):\n",
    "    print(\"Average MSE (lr={0:.10f}): {1:.2f}\".format(lr, jnp.average(jnp.array([result[\"mse\"] for result in results if result[\"lr\"] == lr]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tc.experiment(\"k,projection\", [(10, projections[10]), (500, projections[500])])\n",
    "@tc.experiment(\"basin\", basins)\n",
    "@tc.experiment(\"lr\", jnp.linspace(-5, -4.5, 6))\n",
    "def runner(basin, k, projection, lr):\n",
    "    import pickle\n",
    "    from ealstm.gaip.utils import MSE\n",
    "\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from timecast.learners import Sequential, Parallel, Index, PCR\n",
    "    from timecast import smap\n",
    "    from timecast.objectives import residual\n",
    "    from timecast.optim import GradientDescent\n",
    "\n",
    "    import tqdm.notebook as tqdm\n",
    "    \n",
    "    X = pickle.load(open(\"../data/test/{}.p\".format(basin), \"rb\"))\n",
    "    Y = pickle.load(open(\"../data/ealstm/{}.p\".format(basin), \"rb\"))\n",
    "    \n",
    "    history_len = 270\n",
    "    \n",
    "    lstm = Index.partial(index=0)\n",
    "    pcr = PCR.partial(projection=projection, history_len=history_len, history=X[:history_len - 1])\n",
    "    pcr = Sequential.partial(learners=[Index.partial(index=1), pcr])\n",
    "    model, state = Parallel.new(shape=(1, 32), learners=[lstm, pcr])\n",
    "    \n",
    "    optim_def = GradientDescent(learning_rate=(10 ** lr))\n",
    "    optimizer = optim_def.create(model)\n",
    "\n",
    "    # NOTE: difference in indexing convention, so need to pad one row\n",
    "    X_t = X[history_len - 1:]\n",
    "    Y_lstm = jnp.array(Y.qsim)\n",
    "    Y = jnp.array(Y.qobs).reshape(-1, 1)\n",
    "\n",
    "    Y_hat, optimizer, state = smap((Y_lstm, X_t), Y, optimizer, state=state, objective=residual)\n",
    "\n",
    "    return {\"basin\": basin, \"k\": k, \"lr\": lr, \"mse\": MSE(Y, Y_hat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10541f71dbfd48809e97f81004e3ac05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = runner.run(processes=15, tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
