{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsuo/miniconda3/envs/skgaip/lib/python3.7/site-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import jax.numpy as np\n",
    "import tqdm\n",
    "\n",
    "from timecast.utils.ar import historify\n",
    "\n",
    "from tigerforecast.batch.camels_dataloader import get_basin_list\n",
    "from tigerforecast.batch.camels_dataloader import CamelsTXT\n",
    "from tigerforecast.methods.ARStateless_scan import ARStateless_scan\n",
    "from tigerforecast.methods.Gradient_boosting import Gradient_boosting\n",
    "from tigerforecast.utils.download_tools import get_tigerforecast_dir\n",
    "from tigerforecast.utils.optimizers import SGD\n",
    "from tigerforecast.utils.optimizers.losses import batched_mse, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ttic.uchicago.edu/~tewari/lectures/lecture4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = pickle.load(open(\"../data/flood/meta.pkl\", \"rb\"))[\"basins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_to_yhats_LSTM = pickle.load(open(os.path.join(get_tigerforecast_dir(), \"flood_prediction\", \"basin_to_yhats_LSTM\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for basin in tqdm.tqdm(basins):\n",
    "#     usgs_val = CamelsTXT(basin=basin, concat_static=True)\n",
    "#     for data, targets in usgs_val.sequential_batches(batch_size=5000):\n",
    "#         pickle.dump(data, open(\"../data/flood/test/{}.pkl\".format(basin), \"wb\"))\n",
    "#         pickle.dump(targets, open(\"../data/flood/qobs/{}.pkl\".format(basin), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scan_with_W(yhats_LSTM, method_ar, data, targets, dynamic=False):\n",
    "#     yhats_boosted, ys = None, None\n",
    "# #     print(yhats_LSTM.shape)\n",
    "# #     for data, targets in usgs_val.sequential_batches(batch_size=5000):\n",
    "# #         print(data.shape, targets.shape)\n",
    "# #         print(data[0], targets[0])\n",
    "#     data = np.array(data)\n",
    "#     ys = np.array(targets)\n",
    "#     y_true = targets - yhats_LSTM\n",
    "#     y_pred_ar, W = method_ar.predict_and_update(data, y_true)\n",
    "#     yhats_boosted = yhats_LSTM + y_pred_ar.squeeze()\n",
    "#     return yhats_boosted, ys, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01022500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/531 [00:02<20:02,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48434398\n",
      "01031500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/531 [00:04<20:21,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9334514\n",
      "01047000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/531 [00:06<20:09,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2708772\n",
      "01052500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/531 [00:09<20:05,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5983096\n",
      "01054200 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/531 [00:11<25:17,  2.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88ae684f42d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#     loss, nse = float(loss), float(nse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/skgaip/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/skgaip/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_lexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_force\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for basin in tqdm.tqdm(basins):\n",
    "    SEQUENCE_LENGTH = 270\n",
    "    INPUT_DIM = 32\n",
    "\n",
    "    b_threshold = 1e-4\n",
    "    eta = 0.008\n",
    "\n",
    "    W_lr_best_pairs = [\n",
    "            (0.03, 2e-5),\n",
    "            (0.05, 2e-5),\n",
    "            (0.07, 2e-5),\n",
    "            (0.09, 2e-5),\n",
    "        ]\n",
    "\n",
    "    method_ids = []\n",
    "\n",
    "    for W_threshold, lr in W_lr_best_pairs:\n",
    "        project_threshold = {\"W_lnm\": W_threshold, \"b\": b_threshold}\n",
    "        optim_ar = SGD(loss=batched_mse, learning_rate=lr, clip_grad=False)\n",
    "        method_ar = ARStateless_scan()\n",
    "        method_ar.initialize(\n",
    "            n=INPUT_DIM,\n",
    "            m=1,\n",
    "            l=SEQUENCE_LENGTH,\n",
    "            optimizer=optim_ar,\n",
    "            project_threshold=project_threshold,\n",
    "            scan_mode=True,\n",
    "        )\n",
    "        method_ids.append(method_ar)\n",
    "\n",
    "    method_boosting = Gradient_boosting()\n",
    "    method_boosting.initialize(\n",
    "        method_ids,\n",
    "        X_shape=(270, 32),\n",
    "        Y_shape=(),\n",
    "        loss=batched_mse,\n",
    "        eta=eta,\n",
    "        proxy_loss=\"original\",\n",
    "        W_update_rule=\"GECO\",\n",
    "    )\n",
    "\n",
    "    yhats_LSTM = np.array(basin_to_yhats_LSTM[basin])\n",
    "    X = pickle.load(open(\"../data/flood/test/{}.pkl\".format(basin), \"rb\"))\n",
    "    Y = pickle.load(open(\"../data/flood/qobs/{}.pkl\".format(basin), \"rb\"))\n",
    "    \n",
    "    y_true = Y - yhats_LSTM\n",
    "    y_pred_ar, W = method_boosting.predict_and_update(X, y_true)\n",
    "    yhats = yhats_LSTM + y_pred_ar.squeeze()\n",
    "\n",
    "#     W_entropy = float(-1 * np.sum(W * np.log2(W)))\n",
    "\n",
    "    loss = ((Y - yhats) ** 2).mean()\n",
    "#     ys_mean = Y.mean()\n",
    "\n",
    "#     nse = 1 - ((Y - yhats) ** 2).sum() / ((Y - ys_mean) ** 2).sum()\n",
    "#     loss, nse = float(loss), float(nse)\n",
    "    \n",
    "    print(basin, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin in tqdm.tqdm(basins):\n",
    "    SEQUENCE_LENGTH = 270\n",
    "    INPUT_DIM = 32\n",
    "\n",
    "    b_threshold = 1e-4\n",
    "\n",
    "    W_lr_best_pairs = [\n",
    "            (0.03, 2e-5),\n",
    "            (0.05, 2e-5),\n",
    "            (0.07, 2e-5),\n",
    "            (0.09, 2e-5),\n",
    "        ]\n",
    "\n",
    "    method_ids = []\n",
    "\n",
    "    for W_threshold, lr in W_lr_best_pairs:\n",
    "        project_threshold = {\"W_lnm\": W_threshold, \"b\": b_threshold}\n",
    "        optim_ar = SGD(loss=batched_mse, learning_rate=lr, clip_grad=False)\n",
    "        method_ar = ARStateless_scan()\n",
    "        method_ar.initialize(\n",
    "            n=INPUT_DIM,\n",
    "            m=1,\n",
    "            l=SEQUENCE_LENGTH,\n",
    "            optimizer=optim_ar,\n",
    "            project_threshold=project_threshold,\n",
    "            scan_mode=True,\n",
    "        )\n",
    "        method_ids.append(method_ar)\n",
    "\n",
    "    method_boosting = Gradient_boosting()\n",
    "    method_boosting.initialize(\n",
    "        method_ids,\n",
    "        X_shape=(270, 32),\n",
    "        Y_shape=(),\n",
    "        loss=batched_mse,\n",
    "        eta=eta,\n",
    "        proxy_loss=\"original\",\n",
    "        W_update_rule=\"GECO\",\n",
    "    )\n",
    "\n",
    "    usgs_val = CamelsTXT(basin=basin, concat_static=True)\n",
    "    yhats_LSTM = np.array(basin_to_yhats_LSTM[basin])\n",
    "\n",
    "    yhats, ys, W = scan_with_W(\n",
    "        yhats_LSTM, method_boosting, usgs_val, dynamic=False\n",
    "    )\n",
    "    W_entropy = float(-1 * np.sum(W * np.log2(W)))\n",
    "\n",
    "    loss = ((ys - yhats) ** 2).mean()\n",
    "    ys_mean = ys.mean()\n",
    "\n",
    "    nse = 1 - ((ys - yhats) ** 2).sum() / ((ys - ys_mean) ** 2).sum()\n",
    "    loss, nse = float(loss), float(nse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
