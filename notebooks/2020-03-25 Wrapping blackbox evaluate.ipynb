{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import jax\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from timecast.learners import AR\n",
    "from timecast.learners._ar import _ar_predict, _ar_batch_window\n",
    "from timecast.utils.numpy import ecdf\n",
    "from timecast.utils.losses import MeanSquareError\n",
    "import torch\n",
    "\n",
    "from ealstm.main import get_basin_list, load_attributes, Model, GLOBAL_SETTINGS, evaluate\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap EALSTM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfg(cfg_path):\n",
    "    cfg = json.load(open(cfg_path, \"r\"))\n",
    "    cfg[\"camels_root\"] = Path(cfg[\"camels_root\"])\n",
    "    cfg[\"run_dir\"] = Path(cfg[\"run_dir\"])\n",
    "    cfg.update(GLOBAL_SETTINGS)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from timecast.learners import BaseLearner\n",
    "\n",
    "from ealstm.main import DEVICE\n",
    "from ealstm.main import evaluate_basin\n",
    "from ealstm.main import Model\n",
    "from ealstm.papercode.datautils import reshape_data\n",
    "        \n",
    "class FloodLSTM(BaseLearner):\n",
    "    def __init__(self, cfg_path, input_dim=5, output_dim=1):\n",
    "        self._input_dim = input_dim,\n",
    "        self._output_dim = output_dim\n",
    "        \n",
    "        self.cfg = load_cfg(cfg_path)\n",
    "        self.model = Model(input_size_dyn=(5 if (self.cfg[\"no_static\"] or not self.cfg[\"concat_static\"]) else 32),\n",
    "                           input_size_stat=(0 if self.cfg[\"no_static\"] else 27),\n",
    "                           hidden_size=self.cfg[\"hidden_size\"],\n",
    "                           dropout=self.cfg[\"dropout\"],\n",
    "                           concat_static=self.cfg[\"concat_static\"],\n",
    "                           no_static=self.cfg[\"no_static\"]).to(DEVICE)\n",
    "        \n",
    "        weight_file = os.path.join(self.cfg[\"run_dir\"], \"model_epoch30.pt\")\n",
    "        self.model.load_state_dict(torch.load(weight_file, map_location=DEVICE))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Assumes we get one basin's data at a time\n",
    "        \"\"\"\n",
    "        y = np.ones((X.shape[0], 1))\n",
    "        X, y = reshape_data(X, y, self.cfg[\"seq_length\"])\n",
    "        \n",
    "        X = torch.from_numpy(X.astype(np.float32))\n",
    "        y = torch.from_numpy(y.astype(np.float32))\n",
    "        \n",
    "        loader = DataLoader(TensorDataset(X, y), batch_size=1024, shuffle=False)\n",
    "        preds, obs = evaluate_basin(self.model, loader)\n",
    "        return preds\n",
    "        \n",
    "    def update(self, X, y, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ealstm.main import GLOBAL_SETTINGS\n",
    "from ealstm.main import get_basin_list\n",
    "from ealstm.main import load_attributes\n",
    "from ealstm.papercode.datasets import CamelsTXT\n",
    "\n",
    "class FloodData():\n",
    "    def __init__(self, cfg_path):\n",
    "        self.cfg =load_cfg(cfg_path)\n",
    "        self.basins = get_basin_list()\n",
    "        self.db_path = os.path.join(self.cfg[\"run_dir\"], \"attributes.db\")\n",
    "        self.attributes = load_attributes(db_path=self.db_path,\n",
    "                                          basins=self.basins,\n",
    "                                          drop_lat_lon=True)\n",
    "        \n",
    "    def generator(self, is_train=False, with_attributes=True):\n",
    "        for basin in self.basins:\n",
    "            ds_test = CamelsTXT(camels_root=self.cfg[\"camels_root\"],\n",
    "                                basin=basin,\n",
    "                                dates=[GLOBAL_SETTINGS[\"val_start\"], GLOBAL_SETTINGS[\"val_end\"]],\n",
    "                                is_train=is_train,\n",
    "                                seq_length=self.cfg[\"seq_length\"],\n",
    "                                with_attributes=True,\n",
    "                                attribute_means=self.attributes.mean(),\n",
    "                                attribute_stds=self.attributes.std(),\n",
    "                                concat_static=self.cfg[\"concat_static\"],\n",
    "                                db_path=self.db_path,\n",
    "                                reshape=False,\n",
    "                                torchify=False\n",
    "                               )\n",
    "            X = np.concatenate((ds_test.x, np.tile(np.array(ds_test.attributes), (ds_test.x.shape[0], 1))), axis=1)\n",
    "            yield X, ds_test.y, basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = pickle.load(open(\"../ealstm/runs/run_2503_0429_seed283956/lstm_seed283956.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"/home/dsuo/src/toy_flood/ealstm/runs/run_2503_0429_seed283956/cfg.json\"\n",
    "run_cfg = load_cfg(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FloodData(cfg_path)\n",
    "flood_lstm = FloodLSTM(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a4f11418f649bca3e98672ff9ebc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=531.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "date_range = pd.date_range(start=GLOBAL_SETTINGS[\"val_start\"], end=GLOBAL_SETTINGS[\"val_end\"])\n",
    "for X, y, basin in tqdm.tqdm(data.generator(), total=len(data.basins)):\n",
    "    pred = flood_lstm.predict(X)\n",
    "    true = y[run_cfg[\"seq_length\"] - 1:]\n",
    "    df = pd.DataFrame(data={\"qobs\": true.ravel(), \"qsim\": pred.ravel()}, index=date_range)\n",
    "    results[basin] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c8ebc11fd847a1986d3ce5ba758ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=531.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for basin in tqdm.tqdm(data.basins):\n",
    "    np.testing.assert_array_almost_equal(results[basin], ea[basin], decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating `flood_prediction`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PYTHON_VERSION=cp38  # alternatives: cp36, cp37, cp38\n",
    "CUDA_VERSION=cuda102  # alternatives: cuda92, cuda100, cuda101, cuda102\n",
    "PLATFORM=linux_x86_64  # alternatives: linux_x86_64\n",
    "BASE_URL='https://storage.googleapis.com/jax-releases'\n",
    "pip install --upgrade $BASE_URL/$CUDA_VERSION/jaxlib-0.1.42-$PYTHON_VERSION-none-$PLATFORM.whl\n",
    "\n",
    "pip install --upgrade jax  # install jax\n",
    "pip install h5py numba\n",
    "conda install pytorch torchvision -c pytorch\n",
    "\n",
    "git clone https://github.com/kratzert/ealstm_regional_modeling tigerforecast/data/ealstm_regional_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timecast.optim import SGD\n",
    "from timecast.learners import BaseLearner\n",
    "\n",
    "REG = 0.0\n",
    "TRAINING_STEPS = 1e6\n",
    "BATCH_SIZE = 1\n",
    "SEQUENCE_LENGTH = 270\n",
    "HIDDEN_DIM = 256\n",
    "DP_RATE = 0.0\n",
    "LR_AR = 1e-5\n",
    "AR_INPUT_DIM=32\n",
    "AR_OUTPUT_DIM=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax.numpy as np\n",
    "from timecast.utils.losses.core import Loss\n",
    "\n",
    "class BatchedMeanSquareError(Loss):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compute(self, y_pred: np.ndarray, y_true: np.ndarray):\n",
    "        return np.mean(np.mean((y_pred - y_true) ** 2, axis=tuple(range(1, y_true.ndim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import jax\n",
    "\n",
    "def batch_window(X, window_size, offset=0):\n",
    "    num_windows = X.shape[0] - window_size + 1\n",
    "    return np.swapaxes(np.stack([np.roll(X, shift=-(i + offset), axis=0) for i in range(window_size)]), 0, 1)[:num_windows]\n",
    "\n",
    "class ARStateless(BaseLearner):\n",
    "    def __init__(self, input_dim: int, output_dim: int, window_size: int, optimizer=None, loss=None):\n",
    "        self._input_dim = input_dim\n",
    "        self._output_dim = output_dim\n",
    "        self._window_size = window_size\n",
    "        self._optimizer = optimizer or SGD()\n",
    "        self._loss = loss or BatchedMeanSquareError()\n",
    "        \n",
    "        W = np.zeros((window_size, input_dim, output_dim))\n",
    "        b = np.zeros((output_dim, 1))\n",
    "        self._params = {\"W\": W, \"b\": b}\n",
    "        \n",
    "        def _predict(params, x):\n",
    "            print(params[\"W\"].shape, params[\"b\"].shape, x.shape)\n",
    "            return np.tensordot(params[\"W\"], x, ([0, 1], [0, 1])) + params[\"b\"]\n",
    "        \n",
    "        self._predict_jit = jax.jit(lambda params, X: _predict(params, X))\n",
    "        \n",
    "        self._grad = jax.jit(jax.grad(lambda params, X, y: self._loss.compute(self._predict_jit(params, X), y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return jax.vmap(self._predict_jit, in_axes=(None, 0))(self._params, X).reshape(-1, 1)\n",
    "\n",
    "    def update(self, X, y):\n",
    "        gradients = jax.vmap(self._grad, in_axes=({\"W\": None, \"b\": None}, 0, 0), out_axes=0)(self._params, X, y)\n",
    "        gradients[\"W\"] = gradients[\"W\"].mean(axis=0)\n",
    "        gradients[\"b\"] = gradients[\"b\"].mean(axis=0)\n",
    "        self._params = self._optimizer.update(self._params, gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FloodData(cfg_path)\n",
    "lstm_pred = pickle.load(open(\"../ealstm/runs/run_2503_0429_seed283956/lstm_seed283956.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, basin = next(data.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 32, 1) (1, 1) (270, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar._predict_jit(ar._params, batch_window(X, data.cfg[\"seq_length\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3652, 2)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_pred[basin].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917c244431ed4f0090c4da0c0a959b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=531.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "7344.714 7338.269\n",
      "01022500 0.59074104 0.8800156 0.59074104 0.8800156\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "7141.21 7144.5474\n",
      "01031500 1.0027689 0.8932544 0.79675496 0.886635\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "7770.477 7771.0195\n",
      "01047000 1.424904 0.86648476 1.006138 0.8799183\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "8346.02 8345.097\n",
      "01052500 1.7676423 0.8650273 1.1965141 0.87619555\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "9908.52 9890.953\n",
      "01054200 7.349815 0.7506206 2.4271743 0.85108054\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "8030.0264 8018.157\n",
      "01055000 4.5261536 0.7442876 2.7770042 0.8332817\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "6163.7393 6163.4155\n",
      "01057000 0.9297006 0.8734561 2.5131037 0.83902085\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "5748.851 5747.0854\n",
      "01073000 0.8854102 0.86551344 2.309642 0.8423324\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "6143.1934 6140.633\n",
      "01078000 0.6426703 0.89295614 2.124423 0.8479573\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "6565.018 6560.767\n",
      "01123000 0.7917239 0.83917654 1.991153 0.84707916\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "7242.0815 7251.681\n",
      "01134500 1.8118597 0.77957004 1.9748535 0.84094197\n",
      "(270, 32, 1) (1, 1) (270, 32)\n",
      "(270, 32, 1) (1, 1) (270, 32)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "mses = []\n",
    "nses = []\n",
    "for X, y, basin in tqdm.tqdm(data.generator(), total=len(data.basins)):\n",
    "    # We don't need a new SGD each basin; there is no state\n",
    "    sgd = SGD(learning_rate=LR_AR, online=False)\n",
    "    \n",
    "    # Q: why are we starting with new AR each basin?\n",
    "    ar = ARStateless(input_dim=AR_INPUT_DIM, output_dim=AR_OUTPUT_DIM, window_size=data.cfg[\"seq_length\"], optimizer=sgd)\n",
    "    \n",
    "    # Batch data\n",
    "    X = batch_window(X, data.cfg[\"seq_length\"])\n",
    "    Y = np.array(lstm_pred[basin].qobs).reshape(-1, 1)\n",
    "    \n",
    "    Y_hat = np.array(lstm_pred[basin].qsim).reshape(-1, 1)\n",
    "    Y_target = Y - Y_hat\n",
    "\n",
    "    for i in range(0, X.shape[0], BATCH_SIZE):\n",
    "        x = X[i : i + BATCH_SIZE, :, :]\n",
    "        y = Y_target[i : i + BATCH_SIZE, :]\n",
    "\n",
    "        # TODO: we essentially run predict twice\n",
    "        y_ar = ar.predict(x)\n",
    "        ar.update(x, y)\n",
    "        \n",
    "        Y_hat = jax.ops.index_add(Y_hat, jax.ops.index[i : i + BATCH_SIZE, :], y_ar)\n",
    "    \n",
    "    mse = ((Y - Y_hat) ** 2).mean()\n",
    "    nse = 1 - ((Y - Y_hat) ** 2).sum() / ((Y - Y.mean()) ** 2).sum()\n",
    "    results[basin] = {\n",
    "        \"mse\": mse,\n",
    "        \"nse\": nse,\n",
    "        \"count\": X.shape[0]\n",
    "    }\n",
    "    mses.append(mse)\n",
    "    nses.append(nse)\n",
    "    print(Y.sum(), Y_hat.sum())\n",
    "    print(basin, mse, nse, np.mean(np.array(mses)), np.mean(np.array(nses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "- Why `batched_mse` for SGD loss? Is it because of windows?\n",
    "- Are we sure truncating end for batches the right thing to do?\n",
    "- New AR for each basin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
