{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsuo/miniconda3/envs/toy_flood/lib/python3.7/site-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "import jax\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from timecast.learners import AR\n",
    "from timecast.learners._ar import _ar_predict, _ar_batch_window\n",
    "from timecast.utils.numpy import ecdf\n",
    "from timecast.utils.losses import MeanSquareError\n",
    "import torch\n",
    "import matplotlib\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ealstm.gaip import FloodLSTM\n",
    "from ealstm.gaip import FloodData\n",
    "from ealstm.gaip.utils import MSE, NSE\n",
    "\n",
    "from timecast.learners import AR\n",
    "from timecast.optim import SGD\n",
    "\n",
    "cfg_path = \"/home/dsuo/src/toy_flood/ealstm/runs/run_2503_0429_seed283956/cfg.json\"\n",
    "ea_data = pickle.load(open(\"../ealstm/runs/run_2503_0429_seed283956/lstm_seed283956.p\", \"rb\"))\n",
    "flood_data = FloodData(cfg_path)\n",
    "\n",
    "LR_AR = 1e-5\n",
    "AR_INPUT_DIM=32\n",
    "AR_OUTPUT_DIM=1\n",
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b49e4092e04db1881fb3485ab3e9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=531.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "mses = []\n",
    "nses = []\n",
    "for X, y, basin in tqdm.tqdm(flood_data.generator(), total=len(flood_data.basins)):\n",
    "    break\n",
    "    sgd = SGD(learning_rate=LR_AR, online=False)\n",
    "    ar = AR(input_dim=AR_INPUT_DIM,\n",
    "            output_dim=AR_OUTPUT_DIM,\n",
    "            window_size=flood_data.cfg[\"seq_length\"],\n",
    "            optimizer=sgd,\n",
    "            history=X[:flood_data.cfg[\"seq_length\"]],\n",
    "            fit_intercept=True,\n",
    "            constrain=False\n",
    "           )\n",
    "    # NOTE: difference in indexing convention, so need to pad one row\n",
    "    X = np.vstack((X[flood_data.cfg[\"seq_length\"]:], np.ones((1, X.shape[1]))))\n",
    "    Y = np.array(ea_data[basin].qobs).reshape(-1, 1)\n",
    "    \n",
    "    Y_lstm = np.array(ea_data[basin].qsim).reshape(-1, 1)\n",
    "    Y_target = Y - Y_lstm\n",
    "    \n",
    "    Y_ar = ar.predict_and_update(X, Y_target, batch_size=1)\n",
    "    \n",
    "    Y_hat = Y_lstm + Y_ar\n",
    "    \n",
    "    mse = MSE(Y, Y_hat)\n",
    "    nse = NSE(Y, Y_hat)\n",
    "    results[basin] = {\n",
    "        \"mse\": mse,\n",
    "        \"nse\": nse,\n",
    "        \"count\": X.shape[0],\n",
    "        \"avg_mse\": np.mean(np.array(mses)),\n",
    "        \"avg_nse\": np.mean(np.array(nses))\n",
    "    }\n",
    "    mses.append(mse)\n",
    "    nses.append(nse)\n",
    "    print(basin, mse, nse, np.mean(np.array(mses)), np.mean(np.array(nses)))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nn\n",
    "from flax import optim\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_window(X, window_size, offset=0):\n",
    "    num_windows = X.shape[0] - window_size + 1\n",
    "    return np.swapaxes(np.stack([np.roll(X, shift=-(i + offset), axis=0) for i in range(window_size)]), 0, 1)[:num_windows]\n",
    "\n",
    "class ARF(nn.Module):\n",
    "    def apply(self, x, input_features, output_features, window_size, history=None):\n",
    "        \n",
    "        self.history = self.state(\"history\", (window_size, input_features), nn.initializers.zeros)\n",
    "        \n",
    "        if self.is_initializing():\n",
    "            self.history.value = np.vstack((self.history.value, history))[history.shape[0]:]\n",
    "        else:\n",
    "            self.history.value = np.vstack((self.history.value, x))[x.shape[0]:]\n",
    "        \n",
    "        y = nn.DenseGeneral(inputs=self.history.value,\n",
    "                            features=output_features,\n",
    "                            axis=(0, 1),\n",
    "                            batch_dims=(),\n",
    "                            bias=True,\n",
    "                            dtype=jnp.float32,\n",
    "                            kernel_init=nn.initializers.zeros,\n",
    "                            bias_init=nn.initializers.zeros,\n",
    "                            precision=None,\n",
    "                            name=\"linear\"\n",
    "                           )\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nn.stateful() as init_state:\n",
    "    model_def = ARF.partial(input_features=32, output_features=1, window_size=270, history=X[:flood_data.cfg[\"seq_length\"]-1])\n",
    "    ys, params = model_def.init_by_shape(jax.random.PRNGKey(0), [(1, 32)])\n",
    "    model = nn.Model(model_def, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_def = optim.GradientDescent(learning_rate=1e-5)\n",
    "optimizer = optim_def.create(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdac133e9c8b4a3cbdabfacaea435002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_t = X[flood_data.cfg[\"seq_length\"]-1:]\n",
    "result = []\n",
    "for x, y in tqdm.tqdm(zip(X_t, Y_target), total=X_t.shape[0]):\n",
    "    def loss_fn(model):\n",
    "        y_hat = model(x[None, ...])\n",
    "        return jnp.square(y - y_hat).mean(), y_hat\n",
    "    with nn.stateful(init_state) as init_state:\n",
    "        loss, y_hat, grad = optimizer.compute_gradients(loss_fn)\n",
    "        optimizer = optimizer.apply_gradient(grad)\n",
    "        result.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.59074104, dtype=float32)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat = Y_lstm + np.array(result)\n",
    "MSE(Y_hat, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
