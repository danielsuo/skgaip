{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as onp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib\n",
    "import timecast as tc\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR: MSE=2.7122574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dec922c2714cee9da8bcdfe9a6e206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=531.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE: 2.7122573852539062\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from ealstm.gaip.flood_data import FloodData\n",
    "from ealstm.gaip.utils import MSE, NSE\n",
    "from flax import nn\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from timecast.learners import Sequential, Parallel, AR, Index, PCR\n",
    "from timecast import smap\n",
    "from timecast.objectives import residual\n",
    "from timecast.optim import GradientDescent, RMSProp\n",
    "\n",
    "cfg_path = \"../data/models/runs/run_2006_0032_seed444/cfg.json\"\n",
    "ea_data = pickle.load(open(\"../data/models/runs/run_2006_0032_seed444/lstm_seed444.p\", \"rb\"))\n",
    "flood_data = FloodData(cfg_path)\n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "results = {}\n",
    "mses = []\n",
    "nses = []\n",
    "\n",
    "for X, y, basin in tqdm.tqdm(flood_data.generator(), total=531):\n",
    "    lstm = Index.partial(index=0)\n",
    "    ar = AR.partial(history_len=270, history=X[:flood_data.cfg[\"seq_length\"] - 1])\n",
    "    ar = Sequential.partial(learners=[Index.partial(index=1), ar])\n",
    "    model, state = Parallel.new(shape=(1, 32), learners=[lstm, ar])\n",
    "\n",
    "    optim_def = GradientDescent(learning_rate=lr)\n",
    "    optimizer = optim_def.create(model)\n",
    "\n",
    "    # NOTE: difference in indexing convention, so need to pad one row\n",
    "    X_t = X[flood_data.cfg[\"seq_length\"]-1:]\n",
    "    Y_lstm = jnp.array(ea_data[basin].qsim)\n",
    "    Y = jnp.array(ea_data[basin].qobs).reshape(-1, 1)\n",
    "\n",
    "    Y_hat, optimizer, state = smap((Y_lstm, X_t), Y, optimizer, state=state, objective=residual)\n",
    "    model = optimizer.target\n",
    "\n",
    "    mse = MSE(Y, Y_hat)\n",
    "    nse = NSE(Y, Y_hat)\n",
    "    mses.append(mse)\n",
    "    nses.append(nse)\n",
    "\n",
    "    results[basin] = {\n",
    "        \"mse\": mse,\n",
    "        \"nse\": nse,\n",
    "        \"count\": X.shape[0],\n",
    "        \"avg_mse\": jnp.mean(jnp.array(mses)),\n",
    "        \"avg_nse\": jnp.mean(jnp.array(nses))\n",
    "    }\n",
    "    \n",
    "print(\"MSE: {}\".format(jnp.mean(jnp.array(mses))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timecast.learners._ar import _ar_gram\n",
    "from timecast.learners._pcr import _compute_pca_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XTX, XTY = _ar_gram(flood_data.generator(is_train=True), input_dim=32, output_dim=1, history_len=270)\n",
    "# pcr, state = PCR.fit(, input_dim=32, history_len=270, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c1728fa9254b3da2d35c1427e14883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "projections = {}\n",
    "for k in tqdm.tqdm([10, 50, 100, 500, 1000, 5000]):\n",
    "    projections[k] = _compute_pca_projection(XTX.matrix(normalize=True), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tc.experiment(\"k, projection\", projections.items())\n",
    "def runner(k, projection):\n",
    "    import pickle\n",
    "    from ealstm.gaip.flood_data import FloodData\n",
    "    from ealstm.gaip.utils import MSE, NSE\n",
    "    from flax import nn\n",
    "\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from timecast.learners import Sequential, Parallel, AR, Index, PCR\n",
    "    from timecast import smap\n",
    "    from timecast.objectives import residual\n",
    "    from timecast.optim import GradientDescent, RMSProp\n",
    "    \n",
    "    import tqdm.notebook as tqdm\n",
    "\n",
    "    cfg_path = \"../data/models/runs/run_2006_0032_seed444/cfg.json\"\n",
    "    ea_data = pickle.load(open(\"../data/models/runs/run_2006_0032_seed444/lstm_seed444.p\", \"rb\"))\n",
    "    flood_data = FloodData(cfg_path)\n",
    "\n",
    "    lr = 1e-5\n",
    "\n",
    "    results = {}\n",
    "    mses = []\n",
    "    nses = []\n",
    "\n",
    "    for X, y, basin in tqdm.tqdm(flood_data.generator(), total=531):\n",
    "        lstm = Index.partial(index=0)\n",
    "        ar = PCR.partial(projection=projection, history_len=270, history=X[:flood_data.cfg[\"seq_length\"] - 1])\n",
    "        ar = Sequential.partial(learners=[Index.partial(index=1), ar])\n",
    "        model, state = Parallel.new(shape=(1, 32), learners=[lstm, ar])\n",
    "\n",
    "        optim_def = GradientDescent(learning_rate=lr)\n",
    "        optimizer = optim_def.create(model)\n",
    "\n",
    "        # NOTE: difference in indexing convention, so need to pad one row\n",
    "        X_t = X[flood_data.cfg[\"seq_length\"]-1:]\n",
    "        Y_lstm = jnp.array(ea_data[basin].qsim)\n",
    "        Y = jnp.array(ea_data[basin].qobs).reshape(-1, 1)\n",
    "\n",
    "        Y_hat, optimizer, state = smap((Y_lstm, X_t), Y, optimizer, state=state, objective=residual)\n",
    "        model = optimizer.target\n",
    "\n",
    "        mse = MSE(Y, Y_hat)\n",
    "        nse = NSE(Y, Y_hat)\n",
    "        mses.append(mse)\n",
    "        nses.append(nse)\n",
    "\n",
    "        results[basin] = {\n",
    "            \"mse\": mse,\n",
    "            \"nse\": nse,\n",
    "            \"count\": X.shape[0],\n",
    "            \"avg_mse\": jnp.mean(jnp.array(mses)),\n",
    "            \"avg_nse\": jnp.mean(jnp.array(nses))\n",
    "        }\n",
    "    return {\"k\": k, \"mse\": jnp.mean(jnp.array(mses))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487d7c56748341e58c137c96885cae8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = runner.run(processes=6, tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
