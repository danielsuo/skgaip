{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit, grad\n",
    "\n",
    "import numpy.random as rand\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.linalg import solve_discrete_are as dare\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Loss\n",
    "def quad_loss(x, u, Q = None, R = None):\n",
    "    x_contrib = x.T @ x if Q is None else x.T @ Q @ x\n",
    "    u_contrib = u.T @ u if R is None else u.T @ R @ u\n",
    "    \n",
    "    return np.sum(x_contrib + u_contrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buzz_noise(n, t, scale = 0.3):\n",
    "    if(t < 2 * (T // 10)):\n",
    "        return scale * (jnp.sin(jnp.arange(start=n*t, stop=n*(t+1))/(2*np.pi))).reshape((n, 1))\n",
    "    elif(t < 4 * (T // 10)):\n",
    "        return rand.normal(scale = scale, size = (n, 1))\n",
    "    elif(t < 6 * (T // 10)):\n",
    "        return scale * (jnp.sin(jnp.arange(start=n*t, stop=n*(t+1))/(2*np.pi))).reshape((n, 1))\n",
    "    elif(t < 7 * (T // 10)):\n",
    "        return rand.normal(scale = scale, size = (n, 1))\n",
    "    else:\n",
    "        return scale * (jnp.sin(jnp.arange(start=n*t, stop=n*(t+1))/(2*np.pi))).reshape((n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQR(flax.nn.Module):\n",
    "    @classmethod\n",
    "    def init_K(cls, T, A, B, Q=None, R=None):\n",
    "        n, m = B[0].shape\n",
    "        K = jnp.zeros((T, m, n))\n",
    "        \n",
    "        for t in range(T):\n",
    "            if(t % 10 == 0):\n",
    "                # Get system at current time\n",
    "                At, Bt = A[t], B[t]\n",
    "                Qt = jnp.eye(n, dtype=jnp.float32) if Q is None else Q[t]\n",
    "                Rt = jnp.eye(m, dtype=jnp.float32) if R is None else R[t]\n",
    "\n",
    "                # solve the ricatti equation \n",
    "                Xt = dare(At, Bt, Qt, Rt)\n",
    "\n",
    "                #compute LQR gain\n",
    "                Kt = jnp.linalg.inv(Bt.T @ Xt @ Bt + Rt) @ (Bt.T @ Xt @ At)\n",
    "            K = jax.ops.index_update(K, t, Kt)\n",
    "        return K\n",
    "            \n",
    "    def apply(self, x, T, A, B, K, Q=None, R=None):\n",
    "        self.t = self.state(\"t\", shape=())\n",
    "        \n",
    "        if self.is_initializing():\n",
    "            self.t.value = 0\n",
    "        \n",
    "        action = -K[self.t.value] @ x\n",
    "        self.t.value += 1\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsuo/miniconda3/envs/skgaip/lib/python3.7/site-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "T = 1000\n",
    "A = jnp.array([[[1., 1.], [0., 1.]] for t in range(T)])\n",
    "B = jnp.array([[[0.], [2. + jnp.sin(np.pi * t/T)]] for t in range(T)])\n",
    "\n",
    "n, m = 2, 1\n",
    "x0 = jnp.zeros((n, 1))\n",
    "\n",
    "buzz = jnp.asarray(np.asarray([buzz_noise(n, t) for t in range(T)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_K = LQR.init_K(T, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def = LQR.partial(T=T, A=A, B=B, K=init_K)\n",
    "with flax.nn.stateful() as state:\n",
    "    _, params = model_def.init_by_shape(jax.random.PRNGKey(0), [x0.shape])\n",
    "lqr = flax.nn.Model(model_def, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(carry, inputs):\n",
    "    x, state, model = carry\n",
    "    a, b, z = inputs\n",
    "    with flax.nn.stateful(state) as state:\n",
    "        u = model(x)\n",
    "        loss = quad_loss(x, u)\n",
    "        x = a @ x + b @ u + z\n",
    "    return (x, state, model), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, state, lqr), loss = jax.lax.scan(func, (x0, state, lqr), (A, B, buzz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPC(flax.nn.Module):\n",
    "    def apply(self, x, T, A, B, u=None, Q=None, R=None, K=None, start_time = 0, cost_fn = quad_loss, \\\n",
    "        H = 3, HH = 2, lr_scale = 0.0001, lr_scale_decay = 1.0, decay = False, include_bias = True):\n",
    "        \"\"\"\n",
    "        Description: Initialize the dynamics of the model\n",
    "        Args:\n",
    "            A,B (float/numpy.ndarray): system dynamics\n",
    "            H (postive int): history of the controller \n",
    "            HH (positive int): history of the system \n",
    "            K (float/numpy.ndarray): Starting policy (optional). Defaults to LQR gain.\n",
    "            x (float/numpy.ndarray): initial state (optional)\n",
    "        \"\"\"\n",
    "        n, m = B[0].shape # State & Action Dimensions\n",
    "\n",
    "        T -= start_time\n",
    "        \n",
    "        self.t = self.state(\"t\", shape=())\n",
    "        self.w = self.state(\"w\", shape=(H + HH, n, 1), initializer=flax.nn.initializers.zeros)\n",
    "        self.x = self.state(\"x\", shape=(n, 1), initializer=flax.nn.initializers.zeros)\n",
    "        self.u = self.state(\"u\", shape=(m, 1), initializer=flax.nn.initializers.zeros)\n",
    "        self.M = self.state(\"M\", (H, m, n), initializer=flax.nn.initializers.zeros)\n",
    "        self.bias = self.state(\"bias\", (m, 1), initializer=flax.nn.initializers.zeros)\n",
    "        \n",
    "        if self.is_initializing():\n",
    "            self.t.value = 0\n",
    "        \n",
    "        action = -K[self.t.value] @ x\n",
    "        action += jnp.tensordot(self.M.value, self.w.value[-H:], axes=([0, 2], [0, 1]))\n",
    "        action += self.bias.value * include_bias\n",
    "                \n",
    "        # The Surrogate Cost Function\n",
    "        def policy_loss(M, bias, w, t):\n",
    "            y = np.zeros((n, 1))\n",
    "            t0 = t - HH + 1\n",
    "            for h in range(HH - 1):\n",
    "                v = -K[t0 + h] @ y \n",
    "                v += jnp.tensordot(M, w[h : h + H], axes = ([0, 2], [0, 1])) \n",
    "                v += bias\n",
    "                y = A[t0 + h] @ y + B[t0 + h] @ v + w[h + H]\n",
    "            # Don't update state at the end    \n",
    "            v = -K[t] @ y + jnp.tensordot(M, w[h : h + H], axes=([0, 2], [0, 1])) + bias\n",
    "            return cost_fn(y, v)\n",
    "        \n",
    "        if not self.is_initializing():\n",
    "#             if self.t.value >= HH - 1:\n",
    "            # 1. Get gradients\n",
    "            delta_M, delta_bias = grad(policy_loss, (0, 1))(self.M.value,\n",
    "                                                            self.bias.value,\n",
    "                                                            self.w.value,\n",
    "                                                            self.t.value)\n",
    "            # 2. Execute updates\n",
    "            lr = lr_scale_decay / ( 1+ self.t.value) if decay is True else lr_scale\n",
    "            self.M.value -= lr * delta_M\n",
    "            self.bias.value -= lr * delta_bias\n",
    "\n",
    "            val = x - A[self.t.value] @ self.x.value - B[self.t.value] @ self.u.value\n",
    "            self.w.value = jnp.vstack((self.w.value, val[None, :]))[1:]\n",
    "\n",
    "            # 2. Update x\n",
    "            self.x.value = x\n",
    "\n",
    "            # 3. Update u\n",
    "            self.u.value = -K[self.t.value] @ x\n",
    "            self.u.value += jnp.tensordot(self.M.value, self.w.value[-H:], axes=([0, 2], [0, 1]))\n",
    "            self.u.value += (self.bias.value * include_bias) if u is None else u\n",
    "\n",
    "            self.t.value += 1\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_def = GPC.partial(T=T, A=A, B=B, K=init_K, lr_scale=1e-4, lr_scale_decay=1e-3, H=3, HH=3, decay=True, include_bias=True)\n",
    "with flax.nn.stateful() as state:\n",
    "    _, params = model_def.init_by_shape(jax.random.PRNGKey(0), [x0.shape])\n",
    "gpc = flax.nn.Model(model_def, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 ms ± 2.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x, loss = jax.lax.scan(func, (x0, state, gpc), (A, B, buzz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
